{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Diabetes 30‑Day Readmission Prediction\n",
        "This notebook reproduces the end‑to‑end pipeline described in ChatGPT's analysis:\n",
        "data cleaning, exploratory analysis, feature engineering, class balancing, model training,\n",
        "evaluation, and SHAP interpretation.\n",
        "\n",
        "**Dataset files expected in the working directory:**\n",
        "- `diabetic_data.csv`\n",
        "- `IDS_mapping.csv`\n",
        "\n",
        "Install missing libraries before running (e.g. `xgboost`, `shap`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/arjay55/code/pykan-env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import (precision_score, recall_score, f1_score,\n",
        "                             roc_auc_score, confusion_matrix, ConfusionMatrixDisplay)\n",
        "\n",
        "from sklearn.utils import resample\n",
        "import shap\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "sns.set(style='whitegrid')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Load raw data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data shape: (101766, 50)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>encounter_id</th>\n",
              "      <th>patient_nbr</th>\n",
              "      <th>race</th>\n",
              "      <th>gender</th>\n",
              "      <th>age</th>\n",
              "      <th>weight</th>\n",
              "      <th>admission_type_id</th>\n",
              "      <th>discharge_disposition_id</th>\n",
              "      <th>admission_source_id</th>\n",
              "      <th>time_in_hospital</th>\n",
              "      <th>...</th>\n",
              "      <th>citoglipton</th>\n",
              "      <th>insulin</th>\n",
              "      <th>glyburide-metformin</th>\n",
              "      <th>glipizide-metformin</th>\n",
              "      <th>glimepiride-pioglitazone</th>\n",
              "      <th>metformin-rosiglitazone</th>\n",
              "      <th>metformin-pioglitazone</th>\n",
              "      <th>change</th>\n",
              "      <th>diabetesMed</th>\n",
              "      <th>readmitted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2278392</td>\n",
              "      <td>8222157</td>\n",
              "      <td>Caucasian</td>\n",
              "      <td>Female</td>\n",
              "      <td>[0-10)</td>\n",
              "      <td>?</td>\n",
              "      <td>6</td>\n",
              "      <td>25</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>NO</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>149190</td>\n",
              "      <td>55629189</td>\n",
              "      <td>Caucasian</td>\n",
              "      <td>Female</td>\n",
              "      <td>[10-20)</td>\n",
              "      <td>?</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>3</td>\n",
              "      <td>...</td>\n",
              "      <td>No</td>\n",
              "      <td>Up</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Ch</td>\n",
              "      <td>Yes</td>\n",
              "      <td>&gt;30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>64410</td>\n",
              "      <td>86047875</td>\n",
              "      <td>AfricanAmerican</td>\n",
              "      <td>Female</td>\n",
              "      <td>[20-30)</td>\n",
              "      <td>?</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "      <td>...</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>NO</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>500364</td>\n",
              "      <td>82442376</td>\n",
              "      <td>Caucasian</td>\n",
              "      <td>Male</td>\n",
              "      <td>[30-40)</td>\n",
              "      <td>?</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "      <td>...</td>\n",
              "      <td>No</td>\n",
              "      <td>Up</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Ch</td>\n",
              "      <td>Yes</td>\n",
              "      <td>NO</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>16680</td>\n",
              "      <td>42519267</td>\n",
              "      <td>Caucasian</td>\n",
              "      <td>Male</td>\n",
              "      <td>[40-50)</td>\n",
              "      <td>?</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>No</td>\n",
              "      <td>Steady</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Ch</td>\n",
              "      <td>Yes</td>\n",
              "      <td>NO</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 50 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   encounter_id  patient_nbr             race  gender      age weight  \\\n",
              "0       2278392      8222157        Caucasian  Female   [0-10)      ?   \n",
              "1        149190     55629189        Caucasian  Female  [10-20)      ?   \n",
              "2         64410     86047875  AfricanAmerican  Female  [20-30)      ?   \n",
              "3        500364     82442376        Caucasian    Male  [30-40)      ?   \n",
              "4         16680     42519267        Caucasian    Male  [40-50)      ?   \n",
              "\n",
              "   admission_type_id  discharge_disposition_id  admission_source_id  \\\n",
              "0                  6                        25                    1   \n",
              "1                  1                         1                    7   \n",
              "2                  1                         1                    7   \n",
              "3                  1                         1                    7   \n",
              "4                  1                         1                    7   \n",
              "\n",
              "   time_in_hospital  ... citoglipton insulin  glyburide-metformin  \\\n",
              "0                 1  ...          No      No                   No   \n",
              "1                 3  ...          No      Up                   No   \n",
              "2                 2  ...          No      No                   No   \n",
              "3                 2  ...          No      Up                   No   \n",
              "4                 1  ...          No  Steady                   No   \n",
              "\n",
              "   glipizide-metformin  glimepiride-pioglitazone  metformin-rosiglitazone  \\\n",
              "0                   No                        No                       No   \n",
              "1                   No                        No                       No   \n",
              "2                   No                        No                       No   \n",
              "3                   No                        No                       No   \n",
              "4                   No                        No                       No   \n",
              "\n",
              "   metformin-pioglitazone  change diabetesMed readmitted  \n",
              "0                      No      No          No         NO  \n",
              "1                      No      Ch         Yes        >30  \n",
              "2                      No      No         Yes         NO  \n",
              "3                      No      Ch         Yes         NO  \n",
              "4                      No      Ch         Yes         NO  \n",
              "\n",
              "[5 rows x 50 columns]"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "DATA_DIR = Path('/home/arjay55/code/datasets/diabetes+130-us+hospitals+for+years+1999-2008')  # change if files are elsewhere\n",
        "df = pd.read_csv(DATA_DIR / 'diabetic_data.csv')\n",
        "ids_map = pd.read_csv(DATA_DIR / 'IDS_mapping.csv')\n",
        "print(f'Data shape: {df.shape}')\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "After cleaning: (100111, 49)\n"
          ]
        }
      ],
      "source": [
        "# Drop weight (97% missing) and impossible genders\n",
        "df = df[df['gender'] != 'Unknown/Invalid'].copy()\n",
        "df.drop(columns=['weight'], inplace=True)\n",
        "\n",
        "# Replace '?' with 'Unknown'\n",
        "categorical_cols = df.select_dtypes(include='object').columns\n",
        "df[categorical_cols] = df[categorical_cols].replace('?', 'Unknown')\n",
        "\n",
        "# Remove encounters with discharge disposition indicating death/hospice\n",
        "hospice_codes = [11, 19, 20, 21]\n",
        "df = df[~df['discharge_disposition_id'].isin(hospice_codes)]\n",
        "print('After cleaning:', df.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.1 Map admission/disposition/source IDs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "After applying mapping with converted keys:\n",
            "admission_type_id\n",
            " Physician Referral                                52882\n",
            "HMO Referral                                       18738\n",
            "Clinic Referral                                    18226\n",
            " Transfer from another health care facility         5227\n",
            " Transfer from a Skilled Nursing Facility (SNF)     4690\n",
            " Court/Law Enforcement                               320\n",
            " Emergency Room                                       18\n",
            "Transfer from a hospital                              10\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Create mapping for admission_type_id only (since that's what we have)\n",
        "def build_mapping_from_df(df_map):\n",
        "    # Remove any rows with NaN values\n",
        "    df_clean = df_map.dropna()\n",
        "    return dict(zip(df_clean['admission_type_id'], df_clean['description']))\n",
        "\n",
        "# Build the admission type mapping\n",
        "admission_type_mapping = build_mapping_from_df(ids_map)\n",
        "\n",
        "original_dtype = df['admission_type_id'].dtype\n",
        "\n",
        "# Create new mapping with converted keys\n",
        "if original_dtype in ['int64', 'int32', 'float64']:\n",
        "    # Convert string keys to numeric\n",
        "    admission_type_mapping_fixed = {\n",
        "        int(k): v for k, v in admission_type_mapping.items() \n",
        "        if k.isdigit()\n",
        "    }\n",
        "else:\n",
        "    # Keep as strings\n",
        "    admission_type_mapping_fixed = admission_type_mapping\n",
        "\n",
        "# Apply the mapping\n",
        "df['admission_type_id'] = df['admission_type_id'].map(admission_type_mapping_fixed).fillna('Other')\n",
        "\n",
        "print(\"After applying mapping with converted keys:\")\n",
        "print(df['admission_type_id'].value_counts())\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.2 Aggregate ICD‑9 diagnosis codes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>admission_type_id</th>\n",
              "      <th>description</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Emergency</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>Urgent</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Elective</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>Newborn</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Not Available</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62</th>\n",
              "      <td>22</td>\n",
              "      <td>Transfer from hospital inpt/same fac reslt in...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63</th>\n",
              "      <td>23</td>\n",
              "      <td>Born inside this hospital</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64</th>\n",
              "      <td>24</td>\n",
              "      <td>Born outside this hospital</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65</th>\n",
              "      <td>25</td>\n",
              "      <td>Transfer from Ambulatory Surgery Center</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>66</th>\n",
              "      <td>26</td>\n",
              "      <td>Transfer from Hospice</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>67 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   admission_type_id                                        description\n",
              "0                  1                                          Emergency\n",
              "1                  2                                             Urgent\n",
              "2                  3                                           Elective\n",
              "3                  4                                            Newborn\n",
              "4                  5                                      Not Available\n",
              "..               ...                                                ...\n",
              "62                22   Transfer from hospital inpt/same fac reslt in...\n",
              "63                23                          Born inside this hospital\n",
              "64                24                         Born outside this hospital\n",
              "65                25            Transfer from Ambulatory Surgery Center\n",
              "66                26                              Transfer from Hospice\n",
              "\n",
              "[67 rows x 2 columns]"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ids_map"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def diag_category(icd):\n",
        "    try:\n",
        "        icd = str(icd)\n",
        "        code = icd.split('.')[0]  # take 3‑digit root\n",
        "        if code.startswith('V') or code.startswith('E'):\n",
        "            return 'Other'\n",
        "        code = int(code)\n",
        "    except:\n",
        "        return 'Other'\n",
        "    if 390 <= code <= 459 or code == 785:\n",
        "        return 'Circulatory'\n",
        "    if 460 <= code <= 519 or code == 786:\n",
        "        return 'Respiratory'\n",
        "    if 520 <= code <= 579 or code == 787:\n",
        "        return 'Digestive'\n",
        "    if 250 <= code <= 251:\n",
        "        return 'Diabetes' # oversimplified ?\n",
        "    if 800 <= code <= 999:\n",
        "        return 'Injury'\n",
        "    if 710 <= code <= 739:\n",
        "        return 'Musculoskeletal'\n",
        "    if 140 <= code <= 239:\n",
        "        return 'Neoplasms'\n",
        "    if 580 <= code <= 629 or code == 788:\n",
        "        return 'Genitourinary'\n",
        "    return 'Other'\n",
        "\n",
        "for col in ['diag_1', 'diag_2', 'diag_3']:\n",
        "    df[f'{col}_cat'] = df[col].apply(diag_category)\n",
        "\n",
        "df.drop(columns=['diag_1','diag_2','diag_3'], inplace=True)\n",
        "\n",
        "\n",
        "# %% [markdown]\n",
        "# ### 2.3 Simplify medication change indicators"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "df['change'] = (df['change'] == 'Ch').astype(int)\n",
        "df['diabetesMed'] = (df['diabetesMed'] == 'Yes').astype(int)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "all drugs can be labeled as 0,1,2,3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "df.drop(columns=['encounter_id','patient_nbr'], inplace=True, errors='ignore') #??\n",
        "\n",
        "\n",
        "# %% [markdown]\n",
        "# ## 3. Train‑test split & preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train size: (70077, 46) Pos rate: 0.113\n",
            "Test size: (30034, 46) Pos rate: 0.113\n"
          ]
        }
      ],
      "source": [
        "\n",
        "y = (df['readmitted'] == '<30').astype(int)\n",
        "X = df.drop(columns=['readmitted'])\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, stratify=y, random_state=42)\n",
        "\n",
        "print('Train size:', X_train.shape, 'Pos rate:', y_train.mean().round(3))\n",
        "print('Test size:', X_test.shape, 'Pos rate:', y_test.mean().round(3))\n",
        "\n",
        "\n",
        "# %% [markdown]\n",
        "# ### 3.1 Balance training set by random oversampling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Balanced class counts: readmitted\n",
            "0    62127\n",
            "1    62127\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "\n",
        "train = pd.concat([X_train, y_train], axis=1)\n",
        "maj = train[train['readmitted']==0]\n",
        "minu = train[train['readmitted']==1]\n",
        "minu_upsampled = resample(minu, replace=True, n_samples=len(maj), random_state=42)\n",
        "train_bal = pd.concat([maj, minu_upsampled])\n",
        "X_train_bal = train_bal.drop(columns=['readmitted'])\n",
        "y_train_bal = train_bal['readmitted']\n",
        "print('Balanced class counts:', y_train_bal.value_counts())\n",
        "\n",
        "\n",
        "# %% [markdown]\n",
        "# ### 3.2 One‑hot encode categorical variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "cat_feats = X_train_bal.select_dtypes(include='object').columns\n",
        "X_train_bal_enc = pd.get_dummies(X_train_bal, columns=cat_feats, drop_first=True)\n",
        "X_test_enc = pd.get_dummies(X_test, columns=cat_feats, drop_first=True)\n",
        "X_train_bal_enc, X_test_enc = X_train_bal_enc.align(X_test_enc, join='left', axis=1, fill_value=0)\n",
        "\n",
        "# Fix column names to remove special characters that XGBoost doesn't allow\n",
        "def clean_column_name(col_name):\n",
        "    \"\"\"Clean column names by removing special characters that XGBoost doesn't allow\"\"\"\n",
        "    return str(col_name).replace('[', '_').replace(']', '_').replace('<', '_lt_').replace('>', '_gt_').replace(',', '_')\n",
        "\n",
        "X_train_bal_enc.columns = [clean_column_name(col) for col in X_train_bal_enc.columns]\n",
        "X_test_enc.columns = [clean_column_name(col) for col in X_test_enc.columns]\n",
        "\n",
        "# Scale numeric\n",
        "num_feats = X_train_bal_enc.select_dtypes(include=['int64','float64']).columns\n",
        "scaler = StandardScaler()\n",
        "X_train_bal_enc[num_feats] = scaler.fit_transform(X_train_bal_enc[num_feats])\n",
        "X_test_enc[num_feats] = scaler.transform(X_test_enc[num_feats])\n",
        "\n",
        "\n",
        "# %% [markdown]\n",
        "# ## 4. Model training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "logreg = LogisticRegression(max_iter=200, solver='lbfgs', random_state=42)\n",
        "rf = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42)\n",
        "xgb = XGBClassifier(n_estimators=100, max_depth=6, eval_metric='logloss',\n",
        "                    use_label_encoder=False, verbosity=0, random_state=42)\n",
        "\n",
        "logreg.fit(X_train_bal_enc, y_train_bal)\n",
        "rf.fit(X_train_bal_enc, y_train_bal)\n",
        "xgb.fit(X_train_bal_enc, y_train_bal)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def eval_model(name, model):\n",
        "    y_pred = model.predict(X_test_enc)\n",
        "    y_prob = model.predict_proba(X_test_enc)[:,1]\n",
        "    prec = precision_score(y_test, y_pred)\n",
        "    rec = recall_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "    auc = roc_auc_score(y_test, y_prob)\n",
        "    print(f\"{name:20} Precision: {prec:.3f} Recall: {rec:.3f} F1: {f1:.3f} ROC-AUC: {auc:.3f}\")\n",
        "    return y_pred\n",
        "\n",
        "preds = {}\n",
        "preds['Logistic'] = eval_model('Logistic Regression', logreg)\n",
        "preds['RandomForest'] = eval_model('Random Forest', rf)\n",
        "preds['XGBoost'] = eval_model('XGBoost', xgb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define search space with proper types\n",
        "# rf_param_grid = {\n",
        "#     'n_estimators': [50, 100, 200],\n",
        "#     'max_depth': [5, 10, 15, None],\n",
        "#     'min_samples_split': [2, 5, 10],\n",
        "#     'min_samples_leaf': [1, 2, 4],\n",
        "#     'max_features': ['sqrt', 'log2', None],\n",
        "#     'bootstrap': [True, False]\n",
        "# }\n",
        "\n",
        "# Install: pip install optuna\n",
        "# import optuna\n",
        "# from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# def objective(trial):\n",
        "#     # Define hyperparameters to optimize\n",
        "#     params = {\n",
        "#         'n_estimators': trial.suggest_int('n_estimators', 50, 200),\n",
        "#         'max_depth': trial.suggest_int('max_depth', 3, 15),\n",
        "#         'min_samples_split': trial.suggest_int('min_samples_split', 2, 10),\n",
        "#         'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 5),\n",
        "#         'max_features': trial.suggest_categorical('max_features', ['sqrt', 'log2', None]),\n",
        "#         'bootstrap': trial.suggest_categorical('bootstrap', [True, False])\n",
        "#     }\n",
        "    \n",
        "#     model = RandomForestClassifier(**params, random_state=42)\n",
        "#     scores = cross_val_score(model, X_train_bal_enc, y_train_bal, cv=5, scoring='f1')\n",
        "#     return scores.mean()\n",
        "\n",
        "# # Create study and optimize\n",
        "# study = optuna.create_study(direction='maximize')\n",
        "# study.optimize(objective, n_trials=200, n_jobs=10)\n",
        "\n",
        "# print(f\"Best parameters: {study.best_params}\")\n",
        "# print(f\"Best score: {study.best_value}\")\n",
        "\n",
        "# # Train final model with best parameters\n",
        "# best_rf = RandomForestClassifier(**study.best_params, random_state=42)\n",
        "# best_rf.fit(X_train_bal_enc, y_train_bal)\n",
        "\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "best_rf = RandomForestClassifier(n_estimators=91, max_depth=15, min_samples_split=5, min_samples_leaf=1, max_features=None, bootstrap=True, random_state=42)\n",
        "#  execute cross validation = 5 on best_rf\n",
        "scores = cross_val_score(best_rf, X_train_bal_enc, y_train_bal, cv=5, scoring='f1')\n",
        "#print the f1 score\n",
        "print(f\"F1 score from cross-validation: {scores.mean():.3f} ± {scores.std():.3f}\")\n",
        "best_rf.fit(X_train_bal_enc, y_train_bal)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "preds = {}\n",
        "preds['Logistic'] = eval_model('Logistic Regression', logreg)\n",
        "preds['RandomForest'] = eval_model('Random Forest', best_rf)\n",
        "preds['XGBoost'] = eval_model('XGBoost', xgb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "explainer = shap.TreeExplainer(best_rf)\n",
        "shap_values = explainer.shap_values(X_test_enc, check_additivity=False)\n",
        "\n",
        "# Summary plot (bar)\n",
        "shap.summary_plot(shap_values, X_test_enc, plot_type='bar', show=False)\n",
        "plt.title('Mean SHAP Feature Importance')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "pykan-env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
