{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9033e27",
   "metadata": {},
   "source": [
    "# Diabetes 30‑Day Readmission Prediction\n",
    "This notebook reproduces the end‑to‑end pipeline described in ChatGPT's analysis:\n",
    "data cleaning, exploratory analysis, feature engineering, class balancing, model training,\n",
    "evaluation, and SHAP interpretation.\n",
    "\n",
    "**Dataset files expected in the working directory:**\n",
    "- `diabetic_data.csv`\n",
    "- `IDS_mapping.csv`\n",
    "\n",
    "Install missing libraries before running (e.g. `xgboost`, `shap`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71462965",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import (precision_score, recall_score, f1_score,\n",
    "                             roc_auc_score, confusion_matrix, ConfusionMatrixDisplay)\n",
    "\n",
    "from sklearn.utils import resample\n",
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set(style='whitegrid')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b416f5c4",
   "metadata": {},
   "source": [
    "## 1. Load raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b01630e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: (101766, 50)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>encounter_id</th>\n",
       "      <th>patient_nbr</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>weight</th>\n",
       "      <th>admission_type_id</th>\n",
       "      <th>discharge_disposition_id</th>\n",
       "      <th>admission_source_id</th>\n",
       "      <th>time_in_hospital</th>\n",
       "      <th>...</th>\n",
       "      <th>citoglipton</th>\n",
       "      <th>insulin</th>\n",
       "      <th>glyburide-metformin</th>\n",
       "      <th>glipizide-metformin</th>\n",
       "      <th>glimepiride-pioglitazone</th>\n",
       "      <th>metformin-rosiglitazone</th>\n",
       "      <th>metformin-pioglitazone</th>\n",
       "      <th>change</th>\n",
       "      <th>diabetesMed</th>\n",
       "      <th>readmitted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2278392</td>\n",
       "      <td>8222157</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Female</td>\n",
       "      <td>[0-10)</td>\n",
       "      <td>?</td>\n",
       "      <td>6</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>149190</td>\n",
       "      <td>55629189</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Female</td>\n",
       "      <td>[10-20)</td>\n",
       "      <td>?</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>Up</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Ch</td>\n",
       "      <td>Yes</td>\n",
       "      <td>&gt;30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>64410</td>\n",
       "      <td>86047875</td>\n",
       "      <td>AfricanAmerican</td>\n",
       "      <td>Female</td>\n",
       "      <td>[20-30)</td>\n",
       "      <td>?</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>500364</td>\n",
       "      <td>82442376</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Male</td>\n",
       "      <td>[30-40)</td>\n",
       "      <td>?</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>Up</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Ch</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16680</td>\n",
       "      <td>42519267</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Male</td>\n",
       "      <td>[40-50)</td>\n",
       "      <td>?</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>Steady</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Ch</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   encounter_id  patient_nbr             race  gender      age weight  \\\n",
       "0       2278392      8222157        Caucasian  Female   [0-10)      ?   \n",
       "1        149190     55629189        Caucasian  Female  [10-20)      ?   \n",
       "2         64410     86047875  AfricanAmerican  Female  [20-30)      ?   \n",
       "3        500364     82442376        Caucasian    Male  [30-40)      ?   \n",
       "4         16680     42519267        Caucasian    Male  [40-50)      ?   \n",
       "\n",
       "   admission_type_id  discharge_disposition_id  admission_source_id  \\\n",
       "0                  6                        25                    1   \n",
       "1                  1                         1                    7   \n",
       "2                  1                         1                    7   \n",
       "3                  1                         1                    7   \n",
       "4                  1                         1                    7   \n",
       "\n",
       "   time_in_hospital  ... citoglipton insulin  glyburide-metformin  \\\n",
       "0                 1  ...          No      No                   No   \n",
       "1                 3  ...          No      Up                   No   \n",
       "2                 2  ...          No      No                   No   \n",
       "3                 2  ...          No      Up                   No   \n",
       "4                 1  ...          No  Steady                   No   \n",
       "\n",
       "   glipizide-metformin  glimepiride-pioglitazone  metformin-rosiglitazone  \\\n",
       "0                   No                        No                       No   \n",
       "1                   No                        No                       No   \n",
       "2                   No                        No                       No   \n",
       "3                   No                        No                       No   \n",
       "4                   No                        No                       No   \n",
       "\n",
       "   metformin-pioglitazone  change diabetesMed readmitted  \n",
       "0                      No      No          No         NO  \n",
       "1                      No      Ch         Yes        >30  \n",
       "2                      No      No         Yes         NO  \n",
       "3                      No      Ch         Yes         NO  \n",
       "4                      No      Ch         Yes         NO  \n",
       "\n",
       "[5 rows x 50 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "DATA_DIR = Path('/home/arjay55/code/datasets/diabetes+130-us+hospitals+for+years+1999-2008')  # change if files are elsewhere\n",
    "df = pd.read_csv(DATA_DIR / 'diabetic_data.csv')\n",
    "ids_map = pd.read_csv(DATA_DIR / 'IDS_mapping.csv')\n",
    "print(f'Data shape: {df.shape}')\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e477d82c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in ids_map:\n",
      "['admission_type_id', 'description']\n",
      "\n",
      "First few rows:\n",
      "  admission_type_id    description\n",
      "0                 1      Emergency\n",
      "1                 2         Urgent\n",
      "2                 3       Elective\n",
      "3                 4        Newborn\n",
      "4                 5  Not Available\n",
      "\n",
      "DataFrame info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 67 entries, 0 to 66\n",
      "Data columns (total 2 columns):\n",
      " #   Column             Non-Null Count  Dtype \n",
      "---  ------             --------------  ----- \n",
      " 0   admission_type_id  65 non-null     object\n",
      " 1   description        62 non-null     object\n",
      "dtypes: object(2)\n",
      "memory usage: 1.2+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Check the columns in ids_map\n",
    "print(\"Columns in ids_map:\")\n",
    "print(ids_map.columns.tolist())\n",
    "print(\"\\nFirst few rows:\")\n",
    "print(ids_map.head())\n",
    "print(\"\\nDataFrame info:\")\n",
    "print(ids_map.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aef2aee",
   "metadata": {},
   "source": [
    "## 2. Basic cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2dbf25f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After cleaning: (100111, 49)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Drop weight (97% missing) and impossible genders\n",
    "df = df[df['gender'] != 'Unknown/Invalid'].copy()\n",
    "df.drop(columns=['weight'], inplace=True)\n",
    "\n",
    "# Replace '?' with 'Unknown'\n",
    "categorical_cols = df.select_dtypes(include='object').columns\n",
    "df[categorical_cols] = df[categorical_cols].replace('?', 'Unknown')\n",
    "\n",
    "# Remove encounters with discharge disposition indicating death/hospice\n",
    "hospice_codes = [11, 19, 20, 21]\n",
    "df = df[~df['discharge_disposition_id'].isin(hospice_codes)]\n",
    "print('After cleaning:', df.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "697b1c0b",
   "metadata": {},
   "source": [
    "### 2.1 Map admission/disposition/source IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "536f26a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied mapping to admission_type_id. Unique values now:\n",
      "admission_type_id\n",
      "Other    100111\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Create mapping for admission_type_id only (since that's what we have)\n",
    "def build_mapping_from_df(df_map):\n",
    "    # Remove any rows with NaN values\n",
    "    df_clean = df_map.dropna()\n",
    "    return dict(zip(df_clean['admission_type_id'], df_clean['description']))\n",
    "\n",
    "# Build the admission type mapping\n",
    "admission_type_mapping = build_mapping_from_df(ids_map)\n",
    "\n",
    "# Apply the mapping only to admission_type_id\n",
    "df['admission_type_id'] = df['admission_type_id'].map(admission_type_mapping).fillna('Other')\n",
    "\n",
    "print(f\"Applied mapping to admission_type_id. Unique values now:\")\n",
    "print(df['admission_type_id'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac89fe5",
   "metadata": {},
   "source": [
    "### 2.2 Aggregate ICD‑9 diagnosis codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c121d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def diag_category(icd):\n",
    "    try:\n",
    "        icd = str(icd)\n",
    "        code = icd.split('.')[0]  # take 3‑digit root\n",
    "        if code.startswith('V') or code.startswith('E'):\n",
    "            return 'Other'\n",
    "        code = int(code)\n",
    "    except:\n",
    "        return 'Other'\n",
    "    if 390 <= code <= 459 or code == 785:\n",
    "        return 'Circulatory'\n",
    "    if 460 <= code <= 519 or code == 786:\n",
    "        return 'Respiratory'\n",
    "    if 520 <= code <= 579 or code == 787:\n",
    "        return 'Digestive'\n",
    "    if 250 <= code <= 251:\n",
    "        return 'Diabetes'\n",
    "    if 800 <= code <= 999:\n",
    "        return 'Injury'\n",
    "    if 710 <= code <= 739:\n",
    "        return 'Musculoskeletal'\n",
    "    if 140 <= code <= 239:\n",
    "        return 'Neoplasms'\n",
    "    if 580 <= code <= 629 or code == 788:\n",
    "        return 'Genitourinary'\n",
    "    return 'Other'\n",
    "\n",
    "for col in ['diag_1', 'diag_2', 'diag_3']:\n",
    "    df[f'{col}_cat'] = df[col].apply(diag_category)\n",
    "\n",
    "df.drop(columns=['diag_1','diag_2','diag_3'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccdac5a7",
   "metadata": {},
   "source": [
    "### 2.3 Simplify medication change indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b62e316",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df['change'] = (df['change'] == 'Ch').astype(int)\n",
    "df['diabetesMed'] = (df['diabetesMed'] == 'Yes').astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a922cda5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df.drop(columns=['encounter_id','patient_nbr','examide','citoglipton'], inplace=True, errors='ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d487adf1",
   "metadata": {},
   "source": [
    "## 3. Train‑test split & preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a2e2d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y = (df['readmitted'] == '<30').astype(int)\n",
    "X = df.drop(columns=['readmitted'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, stratify=y, random_state=42)\n",
    "\n",
    "print('Train size:', X_train.shape, 'Pos rate:', y_train.mean().round(3))\n",
    "print('Test size:', X_test.shape, 'Pos rate:', y_test.mean().round(3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "421bce30",
   "metadata": {},
   "source": [
    "### 3.1 Balance training set by random oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63038fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train = pd.concat([X_train, y_train], axis=1)\n",
    "maj = train[train['readmitted']==0]\n",
    "minu = train[train['readmitted']==1]\n",
    "minu_upsampled = resample(minu, replace=True, n_samples=len(maj), random_state=42)\n",
    "train_bal = pd.concat([maj, minu_upsampled])\n",
    "X_train_bal = train_bal.drop(columns=['readmitted'])\n",
    "y_train_bal = train_bal['readmitted']\n",
    "print('Balanced class counts:', y_train_bal.value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd4c4fc",
   "metadata": {},
   "source": [
    "### 3.2 One‑hot encode categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a5488b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cat_feats = X_train_bal.select_dtypes(include='object').columns\n",
    "X_train_bal_enc = pd.get_dummies(X_train_bal, columns=cat_feats, drop_first=True)\n",
    "X_test_enc = pd.get_dummies(X_test, columns=cat_feats, drop_first=True)\n",
    "X_train_bal_enc, X_test_enc = X_train_bal_enc.align(X_test_enc, join='left', axis=1, fill_value=0)\n",
    "\n",
    "# Scale numeric\n",
    "num_feats = X_train_bal_enc.select_dtypes(include=['int64','float64']).columns\n",
    "scaler = StandardScaler()\n",
    "X_train_bal_enc[num_feats] = scaler.fit_transform(X_train_bal_enc[num_feats])\n",
    "X_test_enc[num_feats] = scaler.transform(X_test_enc[num_feats])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "670a86db",
   "metadata": {},
   "source": [
    "## 4. Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0df9bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "logreg = LogisticRegression(max_iter=200, solver='lbfgs', random_state=42)\n",
    "rf = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42)\n",
    "xgb = XGBClassifier(n_estimators=100, max_depth=6, eval_metric='logloss',\n",
    "                    use_label_encoder=False, verbosity=0, random_state=42)\n",
    "\n",
    "logreg.fit(X_train_bal_enc, y_train_bal)\n",
    "rf.fit(X_train_bal_enc, y_train_bal)\n",
    "xgb.fit(X_train_bal_enc, y_train_bal)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f255f0",
   "metadata": {},
   "source": [
    "## 5. Evaluation on original test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f19607",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def eval_model(name, model):\n",
    "    y_pred = model.predict(X_test_enc)\n",
    "    y_prob = model.predict_proba(X_test_enc)[:,1]\n",
    "    prec = precision_score(y_test, y_pred)\n",
    "    rec = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    auc = roc_auc_score(y_test, y_prob)\n",
    "    print(f\"{name:20} Precision: {prec:.3f} Recall: {rec:.3f} F1: {f1:.3f} ROC-AUC: {auc:.3f}\")\n",
    "    return y_pred\n",
    "\n",
    "preds = {}\n",
    "preds['Logistic'] = eval_model('Logistic Regression', logreg)\n",
    "preds['RandomForest'] = eval_model('Random Forest', rf)\n",
    "preds['XGBoost'] = eval_model('XGBoost', xgb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "132fad80",
   "metadata": {},
   "source": [
    "### 5.1 Confusion matrix for best model (XGBoost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc59778",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ConfusionMatrixDisplay.from_predictions(y_test, preds['XGBoost'], cmap='Blues')\n",
    "plt.title('XGBoost Confusion Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d725807e",
   "metadata": {},
   "source": [
    "## 6. SHAP interpretation (XGBoost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba98fd77",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "explainer = shap.TreeExplainer(xgb)\n",
    "shap_values = explainer.shap_values(X_test_enc, check_additivity=False)\n",
    "\n",
    "# Summary plot (bar)\n",
    "shap.summary_plot(shap_values, X_test_enc, plot_type='bar', show=False)\n",
    "plt.title('Mean SHAP Feature Importance')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pykan-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
