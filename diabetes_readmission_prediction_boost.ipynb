{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Diabetes 30‑Day Readmission Prediction\n",
    "\n",
    " This notebook reproduces the end‑to‑end pipeline described in ChatGPT's analysis:\n",
    "\n",
    " data cleaning, exploratory analysis, feature engineering, class balancing, model training,\n",
    "\n",
    " evaluation, and SHAP interpretation.\n",
    "\n",
    "\n",
    "\n",
    " **Dataset files expected in the working directory:**\n",
    "\n",
    " - `diabetic_data.csv`\n",
    "\n",
    " - `IDS_mapping.csv`\n",
    "\n",
    "\n",
    "\n",
    " Install missing libraries before running (e.g. `xgboost`, `shap`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import (precision_score, recall_score, f1_score,\n",
    "                             roc_auc_score, confusion_matrix, ConfusionMatrixDisplay)\n",
    "\n",
    "from sklearn.utils import resample\n",
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set(style='whitegrid')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 1. Load raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "DATA_DIR = Path('/home/arjay55/code/datasets/diabetes+130-us+hospitals+for+years+1999-2008')  # change if files are elsewhere\n",
    "df = pd.read_csv(DATA_DIR / 'diabetic_data.csv')\n",
    "ids_map = pd.read_csv(DATA_DIR / 'IDS_mapping.csv')\n",
    "print(f'Data shape: {df.shape}')\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop weight (97% missing) and impossible genders\n",
    "df = df[df['gender'] != 'Unknown/Invalid'].copy()\n",
    "df.drop(columns=['weight'], inplace=True)\n",
    "\n",
    "# Replace '?' with 'Unknown'\n",
    "categorical_cols = df.select_dtypes(include='object').columns\n",
    "df[categorical_cols] = df[categorical_cols].replace('?', 'Unknown')\n",
    "\n",
    "# Remove encounters with discharge disposition indicating death/hospice\n",
    "hospice_codes = [11, 19, 20, 21]\n",
    "df = df[~df['discharge_disposition_id'].isin(hospice_codes)]\n",
    "print('After cleaning:', df.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### 2.1 Map admission/disposition/source IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create mapping for admission_type_id only (since that's what we have)\n",
    "def build_mapping_from_df(df_map):\n",
    "    # Remove any rows with NaN values\n",
    "    df_clean = df_map.dropna()\n",
    "    return dict(zip(df_clean['admission_type_id'], df_clean['description']))\n",
    "\n",
    "# Build the admission type mapping\n",
    "admission_type_mapping = build_mapping_from_df(ids_map)\n",
    "\n",
    "original_dtype = df['admission_type_id'].dtype\n",
    "\n",
    "# Create new mapping with converted keys\n",
    "if original_dtype in ['int64', 'int32', 'float64']:\n",
    "    # Convert string keys to numeric\n",
    "    admission_type_mapping_fixed = {\n",
    "        int(k): v for k, v in admission_type_mapping.items() \n",
    "        if k.isdigit()\n",
    "    }\n",
    "else:\n",
    "    # Keep as strings\n",
    "    admission_type_mapping_fixed = admission_type_mapping\n",
    "\n",
    "# Apply the mapping\n",
    "df['admission_type_id'] = df['admission_type_id'].map(admission_type_mapping_fixed).fillna('Other')\n",
    "\n",
    "print(\"After applying mapping with converted keys:\")\n",
    "print(df['admission_type_id'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### 2.2 Aggregate ICD‑9 diagnosis codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def diag_category(icd):\n",
    "    try:\n",
    "        icd = str(icd)\n",
    "        code = icd.split('.')[0]  # take 3‑digit root\n",
    "        if code.startswith('V') or code.startswith('E'):\n",
    "            return 'Other'\n",
    "        code = int(code)\n",
    "    except:\n",
    "        return 'Other'\n",
    "    if 390 <= code <= 459 or code == 785 or 460 <= code <= 519 or code == 786 or 520 <= code <= 579 or code == 787 or 250 <= code <= 251:\n",
    "        return f'icd_{code}'  # will result to very sparse categories\n",
    "    if 800 <= code <= 999:\n",
    "        return 'Injury'\n",
    "    if 710 <= code <= 739:\n",
    "        return 'Musculoskeletal'\n",
    "    if 140 <= code <= 239:\n",
    "        return 'Neoplasms'\n",
    "    if 580 <= code <= 629 or code == 788:\n",
    "        return 'Genitourinary'\n",
    "    return 'Other'\n",
    "\n",
    "for col in ['diag_1', 'diag_2', 'diag_3']:\n",
    "    df[f'{col}_cat'] = df[col].apply(diag_category)\n",
    "\n",
    "df.drop(columns=['diag_1','diag_2','diag_3'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### 2.3 Simplify medication change indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df['change'] = (df['change'] == 'Ch').astype(int)\n",
    "df['diabetesMed'] = (df['diabetesMed'] == 'Yes').astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " all drugs can be labeled as 0,1,2,3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df.drop(columns=['encounter_id','patient_nbr'], inplace=True, errors='ignore') #??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 3. Train‑test split & preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_column_name(col_name):\n",
    "    \"\"\"Clean column names by removing special characters that XGBoost doesn't allow\"\"\"\n",
    "    return str(col_name).replace('[', '_').replace(']', '_').replace('<', '_lt_').replace('>', '_gt_').replace(',', '_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y = (df['readmitted'] == '<30').astype(int)\n",
    "X = df.drop(columns=['readmitted'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, stratify=y, random_state=42)\n",
    "\n",
    "print('Train size:', X_train.shape, 'Pos rate:', y_train.mean().round(3))\n",
    "print('Test size:', X_test.shape, 'Pos rate:', y_test.mean().round(3))\n",
    "\n",
    "# Fix column names to remove special characters that XGBoost doesn't allow\n",
    "X_train.columns = [clean_column_name(col) for col in X_train.columns]\n",
    "X_test.columns = [clean_column_name(col) for col in X_test.columns]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### 3.1 Balance training set by random oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train = pd.concat([X_train, y_train], axis=1)\n",
    "maj = train[train['readmitted']==0]\n",
    "minu = train[train['readmitted']==1]\n",
    "minu_upsampled = resample(minu, replace=True, n_samples=len(maj), random_state=42)\n",
    "train_bal = pd.concat([maj, minu_upsampled])\n",
    "X_train_bal = train_bal.drop(columns=['readmitted'])\n",
    "y_train_bal = train_bal['readmitted']\n",
    "print('Balanced class counts:', y_train_bal.value_counts())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### 3.2 One‑hot encode categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cat_feats = X_train_bal.select_dtypes(include='object').columns\n",
    "X_train_bal_enc = pd.get_dummies(X_train_bal, columns=cat_feats, drop_first=True)\n",
    "X_test_enc = pd.get_dummies(X_test, columns=cat_feats, drop_first=True)\n",
    "X_train_bal_enc, X_test_enc = X_train_bal_enc.align(X_test_enc, join='left', axis=1, fill_value=0)\n",
    "\n",
    "## haircut\n",
    "X_train_bal_enc.columns = [clean_column_name(col) for col in X_train_bal_enc.columns]\n",
    "X_test_enc.columns = [clean_column_name(col) for col in X_test_enc.columns]\n",
    "\n",
    "# Scale numeric\n",
    "num_feats = X_train_bal_enc.select_dtypes(include=['int64','float64']).columns\n",
    "scaler = StandardScaler()\n",
    "X_train_bal_enc[num_feats] = scaler.fit_transform(X_train_bal_enc[num_feats])\n",
    "X_test_enc[num_feats] = scaler.transform(X_test_enc[num_feats])\n",
    "\n",
    "print(\"Feature engineering completed. Starting model training...\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 4. Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"Initializing models...\")\n",
    "logreg = LogisticRegression(max_iter=1000, solver='lbfgs', random_state=42)\n",
    "rf = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42)\n",
    "xgb = XGBClassifier(n_estimators=100, max_depth=6, eval_metric='logloss',\n",
    "                    use_label_encoder=False, verbosity=0, random_state=42)\n",
    "\n",
    "print(\"Training Logistic Regression...\")\n",
    "logreg.fit(X_train_bal_enc, y_train_bal)\n",
    "print(\"Training Random Forest...\")\n",
    "rf.fit(X_train_bal_enc, y_train_bal)\n",
    "print(\"Training XGBoost...\")\n",
    "xgb.fit(X_train_bal_enc, y_train_bal)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def eval_model(name, model):\n",
    "    y_pred = model.predict(X_test_enc)\n",
    "    y_prob = model.predict_proba(X_test_enc)[:,1]\n",
    "    prec = precision_score(y_test, y_pred)\n",
    "    rec = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    auc = roc_auc_score(y_test, y_prob)\n",
    "    print(f\"{name:20} Precision: {prec:.3f} Recall: {rec:.3f} F1: {f1:.3f} ROC-AUC: {auc:.3f}\")\n",
    "    return y_pred\n",
    "\n",
    "preds = {}\n",
    "preds['Logistic'] = eval_model('Logistic Regression', logreg)\n",
    "preds['RandomForest'] = eval_model('Random Forest', rf)\n",
    "preds['XGBoost'] = eval_model('XGBoost', xgb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define search space with proper types\n",
    "# rf_param_grid = {\n",
    "#     'n_estimators': [50, 100, 200],\n",
    "#     'max_depth': [5, 10, 15, None],\n",
    "#     'min_samples_split': [2, 5, 10],\n",
    "#     'min_samples_leaf': [1, 2, 4],\n",
    "#     'max_features': ['sqrt', 'log2', None],\n",
    "#     'bootstrap': [True, False]\n",
    "# }\n",
    "\n",
    "# Install: pip install optuna\n",
    "# import optuna\n",
    "# from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# def objective(trial):\n",
    "#     # Define hyperparameters to optimize\n",
    "#     params = {\n",
    "#         'n_estimators': trial.suggest_int('n_estimators', 50, 200),\n",
    "#         'max_depth': trial.suggest_int('max_depth', 3, 15),\n",
    "#         'min_samples_split': trial.suggest_int('min_samples_split', 2, 10),\n",
    "#         'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 5),\n",
    "#         'max_features': trial.suggest_categorical('max_features', ['sqrt', 'log2', None]),\n",
    "#         'bootstrap': trial.suggest_categorical('bootstrap', [True, False])\n",
    "#     }\n",
    "    \n",
    "#     model = RandomForestClassifier(**params, random_state=42)\n",
    "#     scores = cross_val_score(model, X_train_bal_enc, y_train_bal, cv=5, scoring='f1')\n",
    "#     return scores.mean()\n",
    "\n",
    "# # Create study and optimize\n",
    "# study = optuna.create_study(direction='maximize')\n",
    "# study.optimize(objective, n_trials=200, n_jobs=10)\n",
    "\n",
    "# print(f\"Best parameters: {study.best_params}\")\n",
    "# print(f\"Best score: {study.best_value}\")\n",
    "\n",
    "# # Train final model with best parameters\n",
    "# best_rf = RandomForestClassifier(**study.best_params, random_state=42)\n",
    "# best_rf.fit(X_train_bal_enc, y_train_bal)\n",
    "\n",
    "import optuna\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "\n",
    "# Define preprocessing steps\n",
    "def create_preprocessing_pipeline():\n",
    "    # Identify categorical and numerical columns\n",
    "    categorical_features = X_train.select_dtypes(include='object').columns.tolist()\n",
    "    numerical_features = X_train.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "    \n",
    "    # Create preprocessor\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', StandardScaler(), numerical_features),\n",
    "            ('cat', OneHotEncoder(drop='first', handle_unknown='ignore'), categorical_features)\n",
    "        ]\n",
    "    )\n",
    "    return preprocessor, categorical_features, numerical_features\n",
    "\n",
    "# Create pipeline with proper order: preprocess -> balance -> model (with Optuna parameters)\n",
    "def create_model_pipeline(trial=None):\n",
    "    preprocessor, _, _ = create_preprocessing_pipeline()\n",
    "    \n",
    "    # If trial is provided, optimize hyperparameters\n",
    "    if trial is not None:\n",
    "        # Optuna hyperparameter suggestions for XGBoost\n",
    "        n_estimators = trial.suggest_int('n_estimators', 50, 500)\n",
    "        max_depth = trial.suggest_int('max_depth', 3, 15)\n",
    "        learning_rate = trial.suggest_float('learning_rate', 0.01, 0.3, log=True)\n",
    "        subsample = trial.suggest_float('subsample', 0.6, 1.0)\n",
    "        colsample_bytree = trial.suggest_float('colsample_bytree', 0.6, 1.0)\n",
    "        reg_alpha = trial.suggest_float('reg_alpha', 0, 1.0)\n",
    "        reg_lambda = trial.suggest_float('reg_lambda', 0, 1.0)\n",
    "        \n",
    "        classifier = XGBClassifier(\n",
    "            n_estimators=n_estimators,\n",
    "            max_depth=max_depth,\n",
    "            learning_rate=learning_rate,\n",
    "            subsample=subsample,\n",
    "            colsample_bytree=colsample_bytree,\n",
    "            reg_alpha=reg_alpha,\n",
    "            reg_lambda=reg_lambda,\n",
    "            eval_metric='logloss',\n",
    "            use_label_encoder=False,\n",
    "            verbosity=0,\n",
    "            random_state=42,\n",
    "            n_jobs=10  # Use all available cores\n",
    "        )\n",
    "    else:\n",
    "        # Use default/best known parameters for XGBoost\n",
    "        classifier = XGBClassifier(\n",
    "            n_estimators=100, max_depth=6, learning_rate=0.1,\n",
    "            subsample=0.8, colsample_bytree=0.8,\n",
    "            eval_metric='logloss', use_label_encoder=False,\n",
    "            verbosity=0, random_state=42\n",
    "        )\n",
    "    \n",
    "    pipeline = ImbPipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('balancer', RandomOverSampler(random_state=42)),\n",
    "        ('classifier', classifier)\n",
    "    ])\n",
    "    return pipeline\n",
    "\n",
    "# Optuna objective function\n",
    "def objective(trial):\n",
    "    # Create pipeline with trial parameters\n",
    "    pipeline = create_model_pipeline(trial)\n",
    "    \n",
    "    # Cross-validation with proper data handling\n",
    "    cv_scores = cross_val_score(\n",
    "        pipeline, X_train, y_train, \n",
    "        cv=4,  # Reduced for faster optimization\n",
    "        scoring='f1',\n",
    "        n_jobs=1  # Reduced to prevent system overload\n",
    "    )\n",
    "    \n",
    "    return cv_scores.mean()\n",
    "\n",
    "# Run Optuna optimization\n",
    "print(\"Starting Optuna hyperparameter optimization...\")\n",
    "study = optuna.create_study(\n",
    "    direction='maximize',\n",
    "    sampler=optuna.samplers.TPESampler(seed=42)\n",
    ")\n",
    "\n",
    "# Optimize with progress callback\n",
    "# def callback(study, trial):\n",
    "#     if trial.number % 5 == 0:\n",
    "#         print(f\"Trial {trial.number}: Best value = {study.best_value:.4f}\")\n",
    "\n",
    "study.optimize(\n",
    "    objective, \n",
    "    n_trials=200,\n",
    "    # callbacks=[callback],\n",
    "    show_progress_bar=True,\n",
    ")\n",
    "\n",
    "# Print optimization results\n",
    "print(f\"\\nOptimization completed!\")\n",
    "print(f\"Best parameters: {study.best_params}\")\n",
    "print(f\"Best CV F1 score: {study.best_value:.4f}\")\n",
    "\n",
    "# Create final pipeline with best parameters\n",
    "print(\"\\nTraining final model with best parameters...\")\n",
    "best_pipeline = create_model_pipeline()\n",
    "\n",
    "# Update the classifier with best parameters from Optuna\n",
    "best_pipeline.named_steps['classifier'].set_params(**study.best_params)\n",
    "\n",
    "# Cross-validation with best parameters\n",
    "final_cv_scores = cross_val_score(best_pipeline, X_train, y_train, cv=5, scoring='f1')\n",
    "print(f\"Final CV F1 score: {final_cv_scores.mean():.3f} ± {final_cv_scores.std():.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nTraining final model with best parameters...\")\n",
    "best_pipeline = create_model_pipeline()\n",
    "\n",
    "# Update the classifier with best parameters from Optuna\n",
    "best_pipeline.named_steps['classifier'].set_params(**study.best_params,random_state=42)\n",
    "\n",
    "# Cross-validation with best parameters\n",
    "final_cv_scores = cross_val_score(best_pipeline, X_train, y_train, cv=5, scoring='f1')\n",
    "print(f\"Final CV F1 score: {final_cv_scores.mean():.3f} ± {final_cv_scores.std():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the final model on all training data\n",
    "best_pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on test set\n",
    "y_pred_test = best_pipeline.predict(X_test)\n",
    "y_prob_test = best_pipeline.predict_proba(X_test)[:, 1]\n",
    "\n",
    "test_f1 = f1_score(y_test, y_pred_test)\n",
    "test_precision = precision_score(y_test, y_pred_test)\n",
    "test_recall = recall_score(y_test, y_pred_test)\n",
    "test_auc = roc_auc_score(y_test, y_prob_test)\n",
    "\n",
    "print(f\"\\nFinal Test Performance:\")\n",
    "print(f\"F1: {test_f1:.3f}\")\n",
    "print(f\"Precision: {test_precision:.3f}\")\n",
    "print(f\"Recall: {test_recall:.3f}\")\n",
    "print(f\"ROC-AUC: {test_auc:.3f}\")\n",
    "\n",
    "# Save the best model for later use\n",
    "best_rf_optimized = best_pipeline.named_steps['classifier']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred_test)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=['No Readmission', '30-day Readmission'], \n",
    "            yticklabels=['No Readmission', '30-day Readmission'])\n",
    "plt.title('Confusion Matrix - Optimized Random Forest')\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nConfusion Matrix:\")\n",
    "print(f\"True Negatives: {cm[0,0]}\")\n",
    "print(f\"False Positives: {cm[0,1]}\")\n",
    "print(f\"False Negatives: {cm[1,0]}\")\n",
    "print(f\"True Positives: {cm[1,1]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = {}\n",
    "preds['XGBoost'] = eval_model('XGBoost', best_pipeline)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHAP Analysis for the optimized Random Forest\n",
    "# We need to extract the classifier from the pipeline and use preprocessed data\n",
    "\n",
    "# Get the preprocessed test data by transforming through the pipeline steps\n",
    "X_test_preprocessed = best_pipeline.named_steps['preprocessor'].transform(X_test)\n",
    "\n",
    "# Get the trained classifier from the pipeline\n",
    "trained_classifier = best_pipeline.named_steps['classifier']\n",
    "\n",
    "# Create SHAP explainer for the Random Forest classifier\n",
    "explainer = shap.TreeExplainer(trained_classifier)\n",
    "\n",
    "# Calculate SHAP values using the preprocessed test data\n",
    "# Note: Using a subset for faster computation\n",
    "sample_size = min(1000, len(X_test_preprocessed))\n",
    "X_test_sample = X_test_preprocessed[:sample_size]\n",
    "\n",
    "print(f\"Computing SHAP values for {sample_size} test samples...\")\n",
    "shap_values = explainer.shap_values(X_test_sample, check_additivity=False)\n",
    "\n",
    "# If binary classification, take the positive class SHAP values\n",
    "if isinstance(shap_values, list) and len(shap_values) == 2:\n",
    "    shap_values = shap_values[1]  # positive class\n",
    "\n",
    "# Get feature names from the preprocessor\n",
    "feature_names = best_pipeline.named_steps['preprocessor'].get_feature_names_out()\n",
    "\n",
    "# Create a DataFrame for easier handling\n",
    "X_test_sample_df = pd.DataFrame(X_test_sample, columns=feature_names)\n",
    "\n",
    "# Summary plot (bar)\n",
    "shap.summary_plot(shap_values, X_test_sample_df, plot_type='bar', show=False)\n",
    "plt.title('Mean SHAP Feature Importance - Optimized Random Forest')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Detailed summary plot\n",
    "shap.summary_plot(shap_values, X_test_sample_df, show=False)\n",
    "plt.title('SHAP Summary Plot - Optimized Random Forest')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diabetes-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
